# Experiements on Dynamic meta embeddings - Take 1
To run the experiment, the following files need to be places in the same folder
- Dataset of words from: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews
- Glove embeddings 300 dims
- Fasttext embeddings 300 dims
- install libraries based on the requirements.txt

## Sources of inspiration
- The following code has been taken from parts of NLP course CSE 538 assignment 2 at Stony Brook University. 
- Dynamic Meta embeddings from Facebook -https://github.com/facebookresearch/DME 

python final.py

After running the experiments copy over the files called embeddings_txt from the results folder and rename them appropriately
then run python calc_bias.py
